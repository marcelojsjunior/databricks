{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e3ce1b-ea8e-4d20-b79b-7876900cdc64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "%md\n",
    "\n",
    "# Construção das Dimensões Analíticas – Modelo Dimensional DEX\n",
    "\n",
    "Este notebook tem como objetivo a criação das tabelas dimensionais que compõem o modelo estrela derivado da camada Bronze (`workspace.ethereum.dex_trades_bronze`). A construção dessas dimensões permite uma organização semântica e otimizada dos dados, facilitando a criação de joins eficientes e análises analíticas consistentes.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Cada dimensão representa uma entidade desnormalizada da realidade de transações em exchanges descentralizadas, como tokens, redes, exchanges, contratos e datas. As dimensões são persistidas em formato Delta e servirão de base para a criação da tabela fato `fato_dex_transacoes`.\n",
    "\n",
    "---\n",
    "\n",
    "## Dimensão `dim_calendario`\n",
    "\n",
    "### Motivação\n",
    "\n",
    "A dimensão calendário foi criada a partir dos dias distintos registrados na coluna `data_transacao`. É fundamental para análise temporal, agregações por mês, dia da semana e identificação de fins de semana.\n",
    "\n",
    "### Etapas realizadas\n",
    "\n",
    "- Extração dos dias únicos da camada Bronze  \n",
    "- Cálculo de colunas derivadas como:  \n",
    "  - `id_data` no formato `yyyyMMdd`  \n",
    "  - Nome do mês e do dia traduzidos para português  \n",
    "  - Sinalização se o dia é fim de semana (sábado ou domingo)  \n",
    "- Utilização de expressões `create_map` para mapear nomes de meses e dias em inglês para português  \n",
    "- Escrita da dimensão `dim_calendario` com partições otimizadas  \n",
    "\n",
    "---\n",
    "\n",
    "## Dimensão `dim_exchange`\n",
    "\n",
    "### Motivação\n",
    "\n",
    "Essa dimensão representa as exchanges descentralizadas envolvidas nas transações. A existência de nomes distintos e protocolos exige uma estrutura padronizada com chave substituta.\n",
    "\n",
    "### Etapas realizadas\n",
    "\n",
    "- Extração de campos distintos: `exchange_nome`, `exchange_nome_completo`, `protocolo`  \n",
    "- Aplicação de funções de limpeza (`lower`, `trim`, `coalesce`)  \n",
    "- Geração de chave substituta (`id_exchange`) usando função hash `sha2` baseada na combinação dos campos  \n",
    "- Escrita em tabela Delta como `dim_exchange`  \n",
    "\n",
    "---\n",
    "\n",
    "## Dimensão `dim_token`\n",
    "\n",
    "### Motivação\n",
    "\n",
    "Tokens aparecem nas transações como moeda base ou moeda de cotação. Esta dimensão unifica os dois contextos para consolidar todos os tokens presentes no histórico.\n",
    "\n",
    "### Etapas realizadas\n",
    "\n",
    "- Seleção dos tokens base (`moeda_base`, `nome_base`, `endereco_base`) e quote (`moeda_quote`, `nome_quote`, `endereco_quote`)  \n",
    "- União das duas fontes em um único DataFrame sem duplicidade  \n",
    "- Geração de chave substituta (`id_token`) com hash sobre `moeda`, `nome_token` e `endereco_token`  \n",
    "- Escrita final como `dim_token`, com granularidade no nível do contrato/token  \n",
    "\n",
    "---\n",
    "\n",
    "## Dimensão `dim_rede`\n",
    "\n",
    "### Motivação\n",
    "\n",
    "Cada transação está associada a uma blockchain (Ethereum, Polygon, etc.). Essa dimensão padroniza e codifica as redes envolvidas.\n",
    "\n",
    "### Etapas realizadas\n",
    "\n",
    "- Extração dos valores distintos da coluna `rede`  \n",
    "- Geração do `id_rede` com hash da `rede` padronizada  \n",
    "- Escrita da dimensão `dim_rede`, permitindo filtro e agregações por blockchain  \n",
    "\n",
    "---\n",
    "\n",
    "## Dimensão `dim_tipo_contrato`\n",
    "\n",
    "### Motivação\n",
    "\n",
    "Algumas transações referenciam o tipo de contrato e o token relacionado ao contrato inteligente (por exemplo, LP Tokens, NFTs ou contratos de DEX).\n",
    "\n",
    "### Etapas realizadas\n",
    "\n",
    "- Extração das colunas `tipo_contrato`, `simbolo_token_contrato` e `nome_token_contrato`  \n",
    "- Remoção de nulos e duplicatas  \n",
    "- Geração de `id_tipo_contrato` com base no hash dessas três informações combinadas  \n",
    "- Escrita da dimensão `dim_tipo_contrato` com o objetivo de categorizar os contratos envolvidos  \n",
    "\n",
    "---\n",
    "\n",
    "## Boas Práticas Aplicadas\n",
    "\n",
    "- Uso de funções determinísticas (`sha2`) para chaves substitutas  \n",
    "- Padronização semântica de campos com `lower`, `trim`, `coalesce`  \n",
    "- Eliminação de duplicidades e nulos antes da persistência  \n",
    "- Escrita em Delta Lake, garantindo versionamento, performance e auditabilidade  \n",
    "- Uso de alias descritivos e consistentes para todas as colunas  \n",
    "\n",
    "---\n",
    "\n",
    "## Próximos Passos\n",
    "\n",
    "- Criação da tabela `fato_dex_transacoes` com chaves substitutas das dimensões  \n",
    "- Enriquecimento da camada Silver com joins entre fatos e dimensões  \n",
    "- Publicação de datasets analíticos com granularidade otimizada  \n",
    "- Desenvolvimento de dashboards exploratórios para:  \n",
    "  - Volume de transações por protocolo e token  \n",
    "  - Gasto de gas por rede  \n",
    "  - Participação de exchanges no mercado DEX  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80b6f48d-44fd-4750-9f83-5fbb726b5907",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Criação da dimensão dim_calendario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "576b187f-46e5-4c74-a7ee-2f47d0227d79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, date_format, dayofmonth, month, year, dayofweek, when,\n",
    "    create_map, lit, lower\n",
    ")\n",
    "\n",
    "# Pegando os dias distintos da Bronze\n",
    "df_datas = spark.table(\"workspace.ethereum.dex_trades_bronze\") \\\n",
    "    .select(\"data_transacao\") \\\n",
    "    .dropna() \\\n",
    "    .distinct()\n",
    "\n",
    "# Criando dicionário para ajustar os nomes dos meses e dos dias de inglês para português\n",
    "mapa_dias = {\n",
    "    \"monday\": \"Segunda-feira\",\n",
    "    \"tuesday\": \"Terça-feira\",\n",
    "    \"wednesday\": \"Quarta-feira\",\n",
    "    \"thursday\": \"Quinta-feira\",\n",
    "    \"friday\": \"Sexta-feira\",\n",
    "    \"saturday\": \"Sábado\",\n",
    "    \"sunday\": \"Domingo\"\n",
    "}\n",
    "\n",
    "mapa_meses = {\n",
    "    \"january\": \"Janeiro\",\n",
    "    \"february\": \"Fevereiro\",\n",
    "    \"march\": \"Março\",\n",
    "    \"april\": \"Abril\",\n",
    "    \"may\": \"Maio\",\n",
    "    \"june\": \"Junho\",\n",
    "    \"july\": \"Julho\",\n",
    "    \"august\": \"Agosto\",\n",
    "    \"september\": \"Setembro\",\n",
    "    \"october\": \"Outubro\",\n",
    "    \"november\": \"Novembro\",\n",
    "    \"december\": \"Dezembro\"\n",
    "}\n",
    "\n",
    "# Descobri que o create_map do Spark pode receber pares chave-valor diretamente como literais.\n",
    "# Para isso, precisei transformar meu dicionário Python em uma sequência achatada com sum(d.items(), ()).\n",
    "# Esse truque gera uma lista do tipo (\"Monday\", \"Segunda-feira\", \"Tuesday\", \"Terça-feira\", ...).\n",
    "# Depois aplico lit() em cada item para transformar em expressão Spark, e passo para create_map.\n",
    "# Com isso, consigo usar meu dicionário como expressão de mapeamento direto no withColumn\n",
    "\n",
    "def dict_to_map_expr(d):\n",
    "    return create_map([lit(x) for x in sum(d.items(), ())])\n",
    "\n",
    "dias_map_expr = dict_to_map_expr(mapa_dias)\n",
    "meses_map_expr = dict_to_map_expr(mapa_meses)\n",
    "\n",
    "# Construindo a dimensão e convertendo nomes para português\n",
    "dim_calendario = df_datas.withColumn(\"id_data\", date_format(\"data_transacao\", \"yyyyMMdd\").cast(\"int\")) \\\n",
    "    .withColumn(\"data\", col(\"data_transacao\")) \\\n",
    "    .withColumn(\"dia\", dayofmonth(\"data_transacao\")) \\\n",
    "    .withColumn(\"mes\", month(\"data_transacao\")) \\\n",
    "    .withColumn(\"nome_mes_en\", lower(date_format(\"data_transacao\", \"MMMM\"))) \\\n",
    "    .withColumn(\"nome_mes\", meses_map_expr[col(\"nome_mes_en\")]) \\\n",
    "    .withColumn(\"ano\", year(\"data_transacao\")) \\\n",
    "    .withColumn(\"nome_dia_en\", lower(date_format(\"data_transacao\", \"EEEE\"))) \\\n",
    "    .withColumn(\"nome_dia\", dias_map_expr[col(\"nome_dia_en\")]) \\\n",
    "    .withColumn(\"fim_de_semana\", when(dayofweek(\"data_transacao\").isin(1, 7), True).otherwise(False)) \\\n",
    "    .drop(\"data_transacao\", \"nome_mes_en\", \"nome_dia_en\")\n",
    "\n",
    "# Salvando a dimensão de calendário no mesmo esquema da Bronze\n",
    "dim_calendario.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.ethereum.dim_calendario\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "945596f6-105f-42de-b1bc-beb3bfd4e82d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Criação da dimensã dim_exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f7b2062-d1e5-4780-9fe6-90aad205a9f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sha2, concat_ws, col, lower, trim, coalesce, lit\n",
    "\n",
    "# Selecionando campos distintos da bronze\n",
    "df_exchange = spark.table(\"workspace.ethereum.dex_trades_bronze\") \\\n",
    "    .select(\n",
    "        col(\"exchange_nome\").alias(\"nome_exchange\"),\n",
    "        col(\"exchange_nome_completo\").alias(\"nome_completo\"),\n",
    "        col(\"protocolo\")\n",
    "    ).dropna().dropDuplicates()\n",
    "\n",
    "# Criando um id com hash como surrogate key\n",
    "#poderia usar outras técnicas mais avançadas como SCD Tipo 2, porém, para o projeto atual manterei a consistência total do hash garantindo que virá igual com coalesce, lowe, trim e lit\n",
    "dim_exchange = df_exchange.withColumn(\n",
    "    \"id_exchange\",\n",
    "    sha2(\n",
    "        concat_ws(\"||\",\n",
    "            coalesce(lower(trim(col(\"nome_exchange\"))), lit(\"\")),\n",
    "            coalesce(lower(trim(col(\"nome_completo\"))), lit(\"\")),\n",
    "            coalesce(lower(trim(col(\"protocolo\"))), lit(\"\"))\n",
    "        ),\n",
    "        256\n",
    "    )\n",
    ")\n",
    "\n",
    "# Reordenando as colunas\n",
    "dim_exchange = dim_exchange.select(\n",
    "    \"id_exchange\", \"nome_exchange\", \"nome_completo\", \"protocolo\"\n",
    ")\n",
    "\n",
    "# Criando a dim_exchange\n",
    "\n",
    "dim_exchange.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.ethereum.dim_exchange\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c1a1fc-7993-4b02-8349-82662c505686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Criando a dimensão dim_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db72d3e3-5c7e-4607-8303-57a79acbc32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, lower, trim, coalesce, lit, concat_ws, sha2\n",
    ")\n",
    "\n",
    "df_token_base = spark.table(\"workspace.ethereum.dex_trades_bronze\").select(\n",
    "    col(\"moeda_base\").alias(\"moeda\"),\n",
    "    col(\"nome_base\").alias(\"nome_token\"),\n",
    "    col(\"endereco_base\").alias(\"endereco_token\")\n",
    ")\n",
    "\n",
    "df_token_quote = spark.table(\"workspace.ethereum.dex_trades_bronze\").select(\n",
    "    col(\"moeda_quote\").alias(\"moeda\"),\n",
    "    col(\"nome_quote\").alias(\"nome_token\"),\n",
    "    col(\"endereco_quote\").alias(\"endereco_token\")\n",
    ")\n",
    "\n",
    "# Linha pra unir os dois tipos de token que podem ser usados nesse tipo de operaão (conceito de mercado financeiro), quero uma dim com todos os tokens distintos, independentemennte se é a moeda base ou quote\n",
    "df_token = df_token_base.union(df_token_quote).dropna().dropDuplicates()\n",
    "\n",
    "dim_token = df_token.withColumn(\n",
    "    \"id_token\",\n",
    "    sha2(\n",
    "        concat_ws(\"||\",\n",
    "            coalesce(lower(trim(col(\"moeda\"))), lit(\"\")),\n",
    "            coalesce(lower(trim(col(\"nome_token\"))), lit(\"\")),\n",
    "            coalesce(lower(trim(col(\"endereco_token\"))), lit(\"\"))\n",
    "        ),\n",
    "        256\n",
    "    )\n",
    ")\n",
    "\n",
    "dim_token = dim_token.select(\n",
    "    \"id_token\", \"moeda\", \"nome_token\", \"endereco_token\"\n",
    ")\n",
    "\n",
    "dim_token.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.ethereum.dim_token\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8e1eeb0-2351-44e8-8dcc-b3195a331f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Criando dimensão rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa482aa2-9c05-4c12-ba09-5c42c6c0fd6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sha2, lower, trim, coalesce, lit\n",
    "\n",
    "df_rede = spark.table(\"workspace.ethereum.dex_trades_bronze\") \\\n",
    "    .select(\"rede\") \\\n",
    "    .dropna() \\\n",
    "    .dropDuplicates()\n",
    "\n",
    "dim_rede = df_rede.withColumn(\n",
    "    \"id_rede\",\n",
    "    sha2(coalesce(lower(trim(col(\"rede\"))), lit(\"\")), 256)\n",
    ")\n",
    "\n",
    "dim_rede = dim_rede.select(\"id_rede\", \"rede\")\n",
    "\n",
    "dim_rede.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.ethereum.dim_rede\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cabae95b-d24c-4b09-b0c9-d6374a7a549b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Criando dimensão dim_tipo_contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cb000fe-cfc4-4876-a86b-93a16202c28e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sha2, lower, trim, coalesce, concat_ws, lit\n",
    "\n",
    "df_tipo_contrato = spark.table(\"workspace.ethereum.dex_trades_bronze\") \\\n",
    "    .select(\n",
    "        col(\"tipo_contrato\"),\n",
    "        col(\"simbolo_token_contrato\").alias(\"simbolo_token\"),\n",
    "        col(\"nome_token_contrato\").alias(\"nome_token\")\n",
    "    ) \\\n",
    "    .dropna(subset=[\"tipo_contrato\", \"nome_token\"]) \\\n",
    "    .dropDuplicates()\n",
    "\n",
    "dim_tipo_contrato = df_tipo_contrato.withColumn(\n",
    "    \"id_tipo_contrato\",\n",
    "    sha2(\n",
    "        concat_ws(\"||\",\n",
    "            coalesce(lower(trim(col(\"tipo_contrato\"))), lit(\"\")),\n",
    "            coalesce(lower(trim(col(\"simbolo_token\"))), lit(\"\")),\n",
    "            coalesce(lower(trim(col(\"nome_token\"))), lit(\"\"))\n",
    "        ), 256\n",
    "    )\n",
    ")\n",
    "\n",
    "dim_tipo_contrato = dim_tipo_contrato.select(\n",
    "    \"id_tipo_contrato\", \"tipo_contrato\", \"simbolo_token\", \"nome_token\"\n",
    ")\n",
    "\n",
    "dim_tipo_contrato.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.ethereum.dim_tipo_contrato\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8573620412588586,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "dimensoes_dex_trade",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
